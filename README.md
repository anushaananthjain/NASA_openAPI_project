# NASA Astronomy App with ML Integration
This project is a web application that integrates various NASA APIs, including the Astronomy Picture of the Day (APOD) and Near Earth Object Web Service (NEOWS). It also features a machine learning (ML) backend for predicting solar flare peak times, and a module for active region evolution classification.

The application is structured into a React frontend, a Node.js proxy backend, and a Python ML backend.

# Features
Astronomy Picture of the Day (APOD): View the APOD for a selected date.

Near Earth Object Web Service (NEOWS): Browse information about Near-Earth Objects. (Note: The frontend currently only has a placeholder for this.)

Solar Flare Peak Time Prediction: Predict the peak time offset of solar flares using a trained LSTM model.

Active Region Evolution Classification: Classify the evolution of active regions based on input features. (Note: This is an additional ML endpoint provided by the Python backend.)

Interactive UI: A user-friendly interface built with React.

Proxy Backend: A Node.js backend to handle API requests and proxy ML predictions, enhancing security and flexibility.

ML Model Training and Plotting: Python script for training the LSTM model and generating insightful plots of model performance.

# Setup and Installation
Prerequisites
Before you begin, ensure you have the following installed:

Node.js (LTS version recommended) and npm or Yarn

Python 3.8+

pip (Python package installer)

# Environment Variables
Both the Node.js backend and the React frontend require environment variables.

Create .env files:

In the backend/ directory, create a file named .env.

In the frontend/ directory, create a file named .env. (Note: For Vite, it's typically .env or .env.local in the project root, but the App.jsx indicates import.meta.env.VITE_APP_API_URL which is usually picked from the root of the Vite project or explicitly in frontend/.env).

Populate .env for Node.js Backend (backend/.env):

NASA_API_KEY=YOUR_NASA_API_KEY_HERE
ML_API_BASE_URL=http://localhost:5001 # Or the URL where your Python ML backend will run
PORT=5000 # Or any preferred port for the Node.js server

Obtain your NASA_API_KEY from NASA API website.

Populate .env for React Frontend (frontend/.env):

VITE_APP_API_URL=http://localhost:5000 # Or the URL where your Node.js proxy backend will run

# Backend Setup (Node.js Proxy)
Navigate to the backend directory:

cd backend

Install dependencies:

npm install
or
yarn install

Start the Node.js proxy server:

npm start
or
node server.js

The server will typically run on http://localhost:5000 (or the PORT specified in your .env).

# ML Backend Setup (Python)
Navigate to the ml_backend directory:

cd ml_backend

Install Python dependencies:

pip install -r requirements.txt

(If requirements.txt is not provided, you'll need to install them manually. Based on the ml_model.py and ml_backend_server.py files, the likely dependencies are flask, flask-cors, numpy, pandas, scikit-learn, tensorflow, matplotlib, seaborn, joblib.)

Example requirements.txt content:

Flask
Flask-Cors
numpy
pandas
scikit-learn
tensorflow
matplotlib
seaborn
joblib

Train the ML Model (Optional but recommended for fresh setup):
First, ensure you have the solar_flare_dataset.csv file in the ml_backend directory. If not, you'll need to provide one that matches the expected format in ml_model.py.

python ml_model.py

This script will:

Load and preprocess the solar_flare_dataset.csv.

Train the LSTM model.

Evaluate the model.

Save the trained model as solar_flare_peak_time_predictor_lstm_model.h5.

Save the scalers as scaler_X.pkl and scaler_y.pkl.

Generate and save plots to public/plots/.

Start the Python ML backend server:

python ml_backend_server.py

The ML server will typically run on http://localhost:5001.

# Frontend Setup (React)
Navigate to the frontend directory:

cd frontend

Install dependencies:

npm install
or
yarn install

Start the React development server:

npm run dev
or
yarn dev

The frontend will typically open in your browser at http://localhost:5173.

# Usage
Ensure both the Node.js proxy server and the Python ML backend server are running.

Open your web browser and navigate to the frontend URL (e.g., http://localhost:5173).

Use the navigation options to explore:

Home Page: Provides navigation links.

APOD: Select a date to view the Astronomy Picture of the Day.

ML Prediction: This section will display a hardcoded example prediction from the ML backend. (The current App.jsx sends a fixed set of parameters).

ML Graphs: This section is intended to display the plots generated by ml_model.py. (The current implementation in App.jsx points to MLGraphsViewer but the actual rendering of plots would need to be implemented within that component, fetching images from the Node.js proxy /plots/:filename endpoint).

NEOWS: This section is a placeholder in the provided frontend.

API Endpoints
Node.js Proxy Backend (backend/server.js)
GET /api/apod?date=<YYYY-MM-DD>: Fetches the Astronomy Picture of the Day for the specified date from NASA's API.

GET /api/neows?start_date=<YYYY-MM-DD>&end_date=<YYYY-MM-DD>: Fetches Near-Earth Object data for the specified date range from NASA's API.

POST /api/ml_predict: Proxies a prediction request to the Python ML backend.

Request Body (JSON):

{
    "total_counts": 50000,
    "x_pos_asec": 100,
    "y_pos_asec": -200,
    "start_hour": 21,
    "start_minute": 29,
    "start_second": 56,
    "end_hour": 21,
    "end_minute": 41,
    "end_second": 48
}

Response Body (JSON): Contains the prediction results from the Python backend.

GET /plots/:filename: Proxies requests to fetch plot images from the Python ML backend's public/plots directory.

Python ML Backend (ml_backend/ml_backend_server.py)
POST /api/ml_predict: Accepts input features for solar flare peak time prediction.

Request Body (JSON): Same as the Node.js /api/ml_predict endpoint.

Response Body (JSON):

{
    "prediction": 1234.56,              // Predicted offset in seconds
    "prediction_formatted_offset": "HH:MM:SS", // Formatted offset
    "predicted_peak_time": "HH:MM:SS",     // Predicted absolute peak time
    "input_data": { ... },             // The input data received
    "timestamp": "YYYY-MM-DDTHH:MM:SSZ" // Timestamp of the prediction
}

GET /api/classify_ar_evolution: (Additional endpoint) Classifies active region evolution based on query parameters.

Query Parameters: magnetic_flux_change, area_change, gradient_value (all float).

Response Body (JSON):

{
    "success": true,
    "active_region_id": "AR-dynamic",
    "predicted_evolution": 0.X, // A numerical prediction, exact meaning depends on model output
    "timestamp": "YYYY-MM-DDTHH:MM:SSZ"
}

GET /plots/<filename>: Serves static plot image files from the public/plots directory.

# Machine Learning Model
The core of the ML prediction is an LSTM (Long Short-Term Memory) neural network.

Model File: solar_flare_peak_time_predictor_lstm_model.h5

Scalers: scaler_X.pkl (for input features) and scaler_y.pkl (for target variable) are used to normalize and denormalize data.

Features: The model uses features such as flare duration, total counts, spatial position (x.pos.asec, y.pos.asec), and cyclical time features (sine/cosine transformations of start/end hours and minutes).

Target: The model predicts the peak offset in seconds from the flare's start time.

The ml_model.py script handles:

Data loading and preprocessing.

Feature engineering, including the calculation of duration.s and the addition of cyclical time features.

MinMaxScaler application for feature and target scaling.

Splitting data into training and testing sets.

Building and training the LSTM model with EarlyStopping for regularization.

Model evaluation (Loss, MAE in scaled and original units).

Saving the trained model and scalers.

Generating and saving plots (training history, actual vs. predicted, residuals) to the public/plots directory.

Contributing
Fork the repository.

Create your feature branch (git checkout -b feature/AmazingFeature).

Commit your changes (git commit -m 'Add some AmazingFeature').

Push to the branch (git push origin feature/AmazingFeature).

Open a Pull Request.

